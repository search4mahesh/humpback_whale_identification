{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "27393d3b533b1928609f3bceda21209b7a08f6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.2 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "0cfaa55cedb7e80727b272bf5b648dc38f93bf62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.2 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.6.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/mahesh/anaconda3/envs/pytorch-env\n",
      "\n",
      "  added / updated specs: \n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-0.24.1              |   py36he6710b0_0        11.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    pandas: 0.24.1-py36he6710b0_0\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-0.24.1        | 11.1 MB   | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "import pretrainedmodels\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../whale-data/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8f62fc320145a438147b857169f6725c88c58274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25361, 2), 5005)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, train_df.Id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "b4fffbaf19f8371fe63f07f8ff72ae4afb0e2dc7"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = train_df.Id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "cc066a56726375d28143b284158716305d200d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9678b103c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.Id.value_counts().iloc[1:].hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "24acf1683033a1e7d882fa4cfca4bdf7a62dd182"
   },
   "outputs": [],
   "source": [
    "RESIZE_H = 160\n",
    "RESIZE_W = 320\n",
    "\n",
    "data_transforms = albumentations.Compose([\n",
    "    albumentations.Resize(RESIZE_H, RESIZE_W),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.RandomContrast(),\n",
    "        albumentations.RandomBrightness(),\n",
    "    ]),\n",
    "    albumentations.ShiftScaleRotate(rotate_limit=10, scale_limit=0.15),\n",
    "    albumentations.JpegCompression(80),\n",
    "    albumentations.HueSaturationValue(),\n",
    "    albumentations.Normalize(),\n",
    "    AT.ToTensor()\n",
    "])\n",
    "\n",
    "data_transforms_test = albumentations.Compose([\n",
    "    albumentations.Resize(RESIZE_H, RESIZE_W),\n",
    "    albumentations.Normalize(),\n",
    "    AT.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "eaef0437168af0b48db1b8cf43589901734606b3"
   },
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    # From here: https://www.kaggle.com/pestipeti/keras-cnn-starter\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "28538a1976383479893384ed691d116fc878845b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahesh/anaconda3/envs/pytorch-env/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y, lab_encoder = prepare_labels(train_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "efffa7e82f50f339aab100fed67835e49dd8da89"
   },
   "outputs": [],
   "source": [
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, datafolder, datatype='train', df=None, transform=None, y=None):\n",
    "        self.datafolder = datafolder\n",
    "        self.datatype = datatype\n",
    "        self.y = y\n",
    "        if self.datatype == 'train':\n",
    "            self.df = df.values\n",
    "        self.image_files_list = [s for s in os.listdir(datafolder)]\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.datatype == 'train':\n",
    "            img_name = os.path.join(self.datafolder, self.df[idx][0])\n",
    "            label = self.y[idx]\n",
    "            \n",
    "        elif self.datatype == 'test':\n",
    "            img_name = os.path.join(self.datafolder, self.image_files_list[idx])\n",
    "            label = np.zeros((NUM_CLASSES,))\n",
    "\n",
    "        img = cv2.imread(img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image=img)['image']\n",
    "        if self.datatype == 'train':\n",
    "            return image, label\n",
    "        elif self.datatype == 'test':\n",
    "            # so that the images will be in a correct order\n",
    "            return image, label, self.image_files_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "52816552dfa11714cb8e7866b422474971f78d82"
   },
   "outputs": [],
   "source": [
    "train_dataset = WhaleDataset(\n",
    "    datafolder='../whale-data/train/', \n",
    "    datatype='train', \n",
    "    df=train_df, \n",
    "    transform=data_transforms, \n",
    "    y=y\n",
    ")\n",
    "\n",
    "test_set = WhaleDataset(\n",
    "    datafolder='../whale-data/test/', \n",
    "    datatype='test', \n",
    "    transform=data_transforms_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "68d634c72ad9eb5b0ebd551661983e3d93e6ce79"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2ba1f48468ed2d2bf427b95d9a03abe12f793280"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/resnext101_64x4d-e77a0586.pth\" to /home/mahesh/.torch/models/resnext101_64x4d-e77a0586.pth\n",
      "100%|██████████| 334703243/334703243 [02:06<00:00, 2645012.98it/s]\n"
     ]
    }
   ],
   "source": [
    "model = pretrainedmodels.resnext101_64x4d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "f6141ad16752e62fd4ed9aa3275cf78abf4f992c"
   },
   "outputs": [],
   "source": [
    "model.avg_pool = nn.AvgPool2d((5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "d7da045079a594c5ce9bc87b1e7e5f7b0a2d0465"
   },
   "outputs": [],
   "source": [
    "model.last_linear = nn.Linear(model.last_linear.in_features, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "a7755b4730cdfef20e2e28c18e1d1b21cb010123"
   },
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "cc485dbfb03f61c128424e7add4c2e487b4ea9bb"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "4f3c57883af3f42ff55d5a34ef1c7dcf5001dbcd"
   },
   "outputs": [],
   "source": [
    "def cuda(x):\n",
    "    return x.cuda(non_blocking=True) if torch.cuda.is_available() else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "23aa1fbfacbf9c73bb3651dd70de1c78c4b21408"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2537/2537 [22:57<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2537/2537 [22:43<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2537/2537 [22:57<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2537/2537 [22:56<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2537/2537 [22:56<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = []\n",
    "    \n",
    "    for batch_i, (data, target) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        data, target = cuda(data), cuda(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.float())\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "e3f5def101bccf9065e00c83f0597a96437bfb81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 796/796 [02:12<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('../whale-data/sample_submission.csv')\n",
    "\n",
    "model.eval()\n",
    "for (data, target, name) in tqdm(test_loader):\n",
    "    data = cuda(data)\n",
    "    output = model(data)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    for i, (e, n) in enumerate(list(zip(output, name))):\n",
    "        sub.loc[sub['Image'] == n, 'Id'] = ' '.join(lab_encoder.inverse_transform(e.argsort()[-5:][::-1]))\n",
    "        \n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
